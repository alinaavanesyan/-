{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB6j7UJZrspj"
      },
      "source": [
        "#### Скачивание модулей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQ0CdiCNs8gP"
      },
      "outputs": [],
      "source": [
        "pip install pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn8sKHhUtHyE"
      },
      "outputs": [],
      "source": [
        "pip install spellchecker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWfrTPJwte1f"
      },
      "outputs": [],
      "source": [
        "pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZXPIFqexfYf"
      },
      "source": [
        "#### **Вспомогательные [файлы](https://drive.google.com/drive/folders/1HGMld4ZghhdL0faOMVLW1ECC2xvzhWf0?usp=sharing):**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzayWXhhvypk"
      },
      "source": [
        "*  uniq_cases.xlsx (список с редкими словами)\n",
        "*  предлоги.txt (список предлогов русского языка)\n",
        "*  даль_словарь.txt (толковый словарь Даля)\n",
        "*  Обучающий корпус.xlsx (размеченные данные Обучающего корпуса)\n",
        "*  main_source_list.txt (токены Основного корпуса)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKve4OsXr5nQ"
      },
      "source": [
        "### **Алгоритм**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "UE6Wm6yZcEwJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\602\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "C:\\Users\\602\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "C:\\Users\\602\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
            "C:\\Users\\602\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "#@title Используем словарь (то есть сперва ищем слово в списке, а если его там нет, уже идем по алгоритму)\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from difflib import SequenceMatcher\n",
        "import unicodedata\n",
        "from itertools import groupby\n",
        "import numpy as np\n",
        "morph = MorphAnalyzer()\n",
        "from spellchecker import SpellChecker\n",
        "russian = SpellChecker(language='ru')\n",
        "\n",
        "def clean_word(word):\n",
        "    if '<w>' in word:\n",
        "        return re.search(r'<w>(.*)</w>', word).group(1)\n",
        "    else:\n",
        "        return word\n",
        "\n",
        "def part_of_speech(word):\n",
        "    if ' ' not in word:\n",
        "        return morph.parse(word)[0].tag.POS\n",
        "    else:\n",
        "        return ''\n",
        "        \n",
        "def lemma_func(word):\n",
        "    if ' ' not in word:\n",
        "        return morph.parse(word)[0].normal_form\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "def tags(tag,word):\n",
        "    if len(tag) == 0 and ' ' not in word:\n",
        "      return morph.parse(word)[0].tag.POS\n",
        "    elif ' ' in word:\n",
        "      return ''\n",
        "    else:\n",
        "      tags = {'существительное': 'NOUN',\n",
        "              'прилагательное': 'ADJF',\n",
        "              'наречие': 'ADVB',\n",
        "              'междометие': 'INTJ',\n",
        "              'предлог': 'PREP'\n",
        "              }\n",
        "      if tag in tags.keys():\n",
        "        return tags[tag]\n",
        "      else:\n",
        "        return tag\n",
        "        \n",
        "df1 = pd.read_excel('Обучающий корпус.xlsx', sheet_name='distinct')\n",
        "df2 = pd.read_excel('Обучающий корпус.xlsx', sheet_name='оставить')\n",
        "uniq_cases = pd.read_excel('uniq_cases.xlsx')\n",
        "\n",
        "with open('предлоги.txt', 'r') as file:\n",
        "    prepos = [line.rstrip() for line in file]\n",
        "with open('даль_словарь.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = [line.rstrip() for line in file]\n",
        "dal_voc = []\n",
        "for line in lines:\n",
        "    if re.search(r'^[А-Я]+', line):\n",
        "      word = re.match(r'^[А-Я]+', line).group(0).lower()\n",
        "      if len(word) > 1:\n",
        "          dal_voc.append(word)\n",
        "\n",
        "new_df = pd.DataFrame()\n",
        "new_df['Было'] = pd.concat([df1['Было'], df2['Token']], ignore_index=True)\n",
        "new_df['Станет'] = pd.concat([df1['Станет'], df2['Token']], ignore_index=True)\n",
        "new_df['Частота'] = pd.concat([df1['Freq(School_Corpus)'], df2['Freq(School_Corpus)']], ignore_index=True)\n",
        "new_df['Станет'] = new_df['Станет'].apply(clean_word)\n",
        "vocab = dal_voc + list(set(new_df['Станет'].tolist()))\n",
        "two_tokens = {'Во-о-оза-ра-за-за-за': 'Во$зараза'} #список слов с двумя токенами можно дополнять\n",
        "\n",
        "def get_corrected1(token):\n",
        "    normalized_word = unicodedata.normalize('NFKC', token)\n",
        "    cleaned_token = ''.join(c for c in normalized_word if not unicodedata.combining(c))\n",
        "    for l in cleaned_token:\n",
        "        if l not in 'АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя-':\n",
        "            cleaned_token = cleaned_token.replace(l, '')\n",
        "    cleaned_token = re.sub(r'(-)\\1+', r'\\1', cleaned_token)\n",
        "    def matchsubstring(m,n):\n",
        "        common = []\n",
        "        while True:\n",
        "            seqMatch = SequenceMatcher(None,m,n)\n",
        "            match = seqMatch.get_matching_blocks()\n",
        "            if len(match) > 1:\n",
        "                for i in range(len(match)-1):\n",
        "                    common.append(m[match[i].a:match[i].a+match[i].size])\n",
        "                if len(n) != match[-2].size+1 and len(m) != match[-2].a+match[-2].size:\n",
        "                    m = m[match[-2].a+match[-2].size:]\n",
        "                else:\n",
        "                    if m[-1] == n[0] and n[0] not in common:\n",
        "                        common.append(n[0])\n",
        "                    break\n",
        "            else:\n",
        "                break\n",
        "        return common\n",
        "\n",
        "    if token in vocab or token.lower() in vocab:\n",
        "        return [token, '']\n",
        "\n",
        "    elif len(token.split('-')) == 2 and token.split('-')[0] in vocab and token.split('-')[1] in vocab and len(token.split('-')[0]) >=4 and len(token.split('-')[1]) >= 4: #редкие сложные сущ.\n",
        "        return [token, '']\n",
        "\n",
        "    elif len(cleaned_token.split('-')) == 2 and morph.parse(cleaned_token.split('-')[0])[0].normal_form in vocab and morph.parse(cleaned_token.split('-')[1])[0].normal_form in vocab:\n",
        "        return [cleaned_token, '']\n",
        "\n",
        "    elif token.replace('-', '').lower() in vocab or token.replace('-', '').lower() in vocab: #случаи скандирования\n",
        "        return [token.replace('-', '').lower(), '']\n",
        "\n",
        "    elif token in prepos:\n",
        "        return [token, 'предлог']\n",
        "\n",
        "    elif re.sub(r'((\\w)(-)?)\\1+', r'\\1', token.lower().replace('-', '')) in vocab and len(re.sub(r'((\\w)(-)?)\\1+', r'\\1', token.lower().replace('-', ''))) > 3: #случаи скандирования\n",
        "        token = re.sub(r'((\\w)(-)?)\\1+', r'\\1', token.lower().replace('-', ''))\n",
        "        if cleaned_token[0].isupper():\n",
        "            token = token.capitalize()\n",
        "        return [token, '']\n",
        "\n",
        "    elif re.sub(r'((\\w)(-)?)\\1+', r'\\1', token.replace('-', '')) in vocab and len(re.sub(r'((\\w)(-)?)\\1+', r'\\1', token.replace('-', ''))) > 3: #случаи скандирования\n",
        "        token = re.sub(r'((\\w)(-)?)\\1+', r'\\1', token.replace('-', ''))\n",
        "        if cleaned_token[0].isupper():\n",
        "            token = token.capitalize()\n",
        "        return [token, '']\n",
        "\n",
        "    elif token.lower() in uniq_cases['Было'].tolist():\n",
        "        token = uniq_cases[uniq_cases['Было'] == token.lower()]['Станет'].item()\n",
        "        if cleaned_token[0].isupper():\n",
        "            token = token.capitalize()\n",
        "        if cleaned_token[cleaned_token.find('-')+1].isupper():\n",
        "            i = token.find('-')+1\n",
        "            token = list(token)\n",
        "            token[i] = token[i].upper()\n",
        "            token = ''.join(token)\n",
        "        return [token, '']\n",
        "\n",
        "    elif len(token.split('-')) == 2 and token.split('-')[1] in vocab and token.split('-')[0][0].isupper() and len(token.split('-')[0]) >=4 and len(token.split('-')[1]) >= 4: #случаи вида Машка-одноклассница\n",
        "        return [token, '']\n",
        "\n",
        "    elif (len(token.split('-')) == 2 and morph.parse(token.split('-')[1])[0].normal_form in vocab and len(token.split('-')[0]) > 1 and len(token.split('-')[0]) <=3 and token.split('-')[0].isupper() and len(token.split('-')[1]) >= 4) or re.search(r'^АБВГД-ейк', token): #ищем аббревиатуры вида ВИЧ-инфекция, АБ-центр\n",
        "        return [token, '']\n",
        "\n",
        "    elif len(token.split('-')) == 2 and token.split('-')[0] in ['аль', 'Аль'] and (morph.parse(token.split('-')[1])[0].normal_form in vocab or token.split('-')[1][0].isupper()):\n",
        "        return [token, '']\n",
        "\n",
        "    elif token.split('-')[0] in ['альт', 'Альт'] and len(token.split('-')) == 2 and len(token.split('-')[1]) > 3:\n",
        "        return [token, '']\n",
        "\n",
        "    elif token.split('-')[0] in ['альт', 'Альт'] and len(token.split('-')) == 3 and token.split('-')[1] == 'а' and len(token.split('-')[2]) > 3:\n",
        "        return [token, '']\n",
        "\n",
        "    elif token in two_tokens.keys():\n",
        "        return [two_tokens[token], '']\n",
        "\n",
        "\n",
        "    else:\n",
        "        cleaned_token = cleaned_token.replace(' ', '')\n",
        "        cleaned_token = cleaned_token.replace('.', '')\n",
        "        word = re.sub(r'(-)\\1+', r'\\1', cleaned_token)\n",
        "        result = []\n",
        "\n",
        "        if len(word.split('-')) == 2: #если в слове только один дефис\n",
        "            if re.search(r'[А-Яа-яЁё]{3,}(?<!то)-то$', word):\n",
        "                if re.search(r'ой|ый|ий|ая|яя|ое|ее|ые|ие|ого|его|ому|ему|ую|юю|им|ым|ом|ем|ых|их|ыми|ими-то$', word): #если слово имеет окончание прилагательного\n",
        "                    result = [word, 'прилагательное']\n",
        "                else:\n",
        "                    result = [word, '']\n",
        "            if re.search(r'^[А-Я][а-я]+-([А-Я][а-я]+-)?[А-Я][а-я]+$', word): #если слово и его части, разделенные дефисом, начинаются с заглавной буквы\n",
        "                #преобразования не нужны, т.к. это имя собственное\n",
        "                if re.search(r'ой|ый|ий|ая|яя|ое|ее|ые|ие|ого|его|ому|ему|ую|юю|им|ым|ом|ем|ых|их|ыми|ими$', word): #если слово имеет окончание прилагательного\n",
        "                    result = [word, 'прилагательное']\n",
        "                else:\n",
        "                    result = [word, 'существительное']\n",
        "            elif re.search(r'^(кое|кой|койни)-(где|как|когда|куда)$', word, re.IGNORECASE): #наречия вида кое-где, кое-когда и т.д.\n",
        "                if 'койни' in word:\n",
        "                    word = word.replace('койни', 'кое')\n",
        "                result = [word, 'наречие']\n",
        "            elif re.search(r'^(кое|кой|койни)-(что|кто)$', word.lower()): #местоимения вида кое-кто в И.п. и В.п.\n",
        "                if 'койни' in word:\n",
        "                    word = word.replace('койни', 'кое')\n",
        "                result = [word, 'местоимение']\n",
        "            elif re.search(r'^(кое|кой|койни)-как(ой|ая|ое|ие|ого|их)$', word, re.IGNORECASE):  #местоимения вида кое-кто в косвенных падежах\n",
        "                if 'койни' in word:\n",
        "                    word = word.replace('койни', 'кое')\n",
        "                result = [word, 'местоимение']\n",
        "            elif re.search(r'^(кто|что|че|чё|как|куда|сколько|когда|где|гдей|чтой|ктой|кого|кому|кого|кем|ком|чей|чего|чево|чиво|чему|чем|чём|чей|чья|чьё|чьи|чьего|чьей|чьих|чьему|чьим|чью|чьим|чьими|чьём)-(то|либо|нибудь|нить|нють|нито)$', word.lower()):\n",
        "                if re.search(r'^(чё|че|чтой|што|чо)-(то|либо|нибудь|нить|нють|нито)$', word.lower()):\n",
        "                    word = re.sub(r'(че|чё|чтой|што|чо)', r'что', word.lower())\n",
        "                elif 'чево' in word.lower() or 'чиво' in word.lower():\n",
        "                    word = re.sub(r'(чево|чиво)', r'чего', word.lower())\n",
        "                elif 'гдей' in word.lower():\n",
        "                    word = word.replace('гдей', 'где')\n",
        "                elif word.startswith('ктой') or word.startswith('Ктой'):\n",
        "                    word = word.replace('ктой', 'кто'); word = word.replace('Ктой', 'Кто')\n",
        "                if 'нють' in word.lower() or 'нито' in word.lower():\n",
        "                    word = re.sub(r'нють|нито', r'нибудь', word, re.IGNORECASE)\n",
        "                if 'как' in word or 'где' in word or 'куда' in word or 'когда' in word:\n",
        "                    result = [word, 'наречие']\n",
        "                else:\n",
        "                    result = [word, 'местоимение']\n",
        "            elif re.search(r'^(как|так)(ой|ая|ое|ие|ого|ово|ой|их|ому|им|ую|ою|ими|ом|у)-(то|ту|либо|нибудь|нить)$', word, re.IGNORECASE): #местоимения вида какой-либо, такой-то\n",
        "                if 'каково' in word.lower():\n",
        "                    word = re.sub(r'каково', 'какого', word); word = re.sub(r'Каково', 'Какого', word)\n",
        "                elif 'таку' in word.lower():\n",
        "                    word = re.sub(r'таку', 'такую', word); word = re.sub(r'Таку', 'Такую', word)\n",
        "                elif 'каку' in word.lower():\n",
        "                    word = re.sub(r'каку', 'какую', word); word = re.sub(r'Каку', 'Какую', word)\n",
        "                if 'ту' in word.lower():\n",
        "                    word = re.sub(r'ту', 'то', word)\n",
        "                result = [word, 'местоимение']\n",
        "\n",
        "            elif re.search(r'^[А-Яа-яЁё]{2,}(о|е)-[а-яё]{2,}(ый|ой|ая|ое|ые|ие|ье|ей|ую|ого|ому|ым|им|ом|их|ее|ими|ых|его|ий|его|ему|им|ем|ыми)$', word, re.IGNORECASE): #прилагательные типа сине-красный\n",
        "                if not re.search(r'о-о', word) and not re.search(r'е-е', word): #исключаем случаи, когда это не составное прил., а растянутая буква в середине слова\n",
        "                    result = [word, 'прилагательное']\n",
        "\n",
        "            elif re.search(r'^по-[а-я]{3,}(ьи|ски|цки|ому|ему)$', word, re.IGNORECASE) or re.search(r'^по-(тво|мо|ихн)ему$', word, re.IGNORECASE) or re.search(r'^по-иному$', word, re.IGNORECASE): #наречия типа по-волчьи\n",
        "                result = [word, 'наречие']\n",
        "\n",
        "            elif re.search(r'^в-[^в][а-я]{2,}(ых|их)$', word, re.IGNORECASE) or re.search(r'^во-[а-я]{3,}(ых|их)$', word, re.IGNORECASE) or word == 'в-восьмых': #штуки типа во-первых\n",
        "                result = [word, 'наречие']\n",
        "\n",
        "            elif re.search(r'^(северо|юго)-(восток|запад)(а|у|ом|е)?$', word, re.IGNORECASE): #северо-запад, юго-восток\n",
        "                result = [word, 'существительное']\n",
        "\n",
        "            elif re.search(r'^(норд|зюйд)-(ост|вест)', word, re.IGNORECASE): #добавить сюда норд, вест\n",
        "                if re.search(r'(ост|вест)(а|у|ом|е)?$', word, re.IGNORECASE): #зюйд-вест\n",
        "                    result = [word, 'существительное']\n",
        "                elif re.search(r'остов|вестов', word, re.IGNORECASE): #норд-остовый (можно добавить перечень окончаний прил.)\n",
        "                    result = [word, 'прилагательное']\n",
        "\n",
        "            elif re.search(r'^(авто|агро|аэро|био|вело|гидро|зоо|кино|макро|микро|метео|мото|нео|радио|теле|стерео|фото|электро)-[а-я]{3,}$', word, re.IGNORECASE):\n",
        "                word = word.replace('-','') #с такими приставками не нужен дефис, удаляем его\n",
        "                result = [word, 'существительное']\n",
        "\n",
        "            elif re.search(r'^(вице|лейб|обер|унтер|ундер|штаб|экс)-[а-я]{3,}$', word, re.IGNORECASE):\n",
        "                if 'ундер' in word:\n",
        "                    word = word.replace('ундер', 'унтер')\n",
        "                result = [word, 'существительное']\n",
        "\n",
        "            elif re.search(f'b/пол-[аеёиоуыэюя][а-я]+$', word) or re.search(f'^пол-л[а-я]+$', word) or re.search(f'^пол-[А-ЯЁ][а-я]+$', word):\n",
        "                result = [word, 'существительное']\n",
        "\n",
        "        if len(result) == 0: #если у нас нет результата\n",
        "\n",
        "            #подсчет согласных и гласных\n",
        "            conson = [x for x in list(word.lower()) if x in 'бвгджзклмнпрстфхцчшцьъ']\n",
        "            vowels = [x for x in list(word.lower()) if x in 'ауоыиэяюёе']\n",
        "\n",
        "            if len(set(conson)) == 0 or len(set(vowels)) == 0: #если слово состоит только из гласных или только из согласных\n",
        "                result = [word, 'междометие']\n",
        "                return result\n",
        "\n",
        "            elif len(set(conson)) == 1 and len(set(vowels)) == 1: #нн-нее ооо-ох\n",
        "                if len([''.join(g) for _, g in groupby(word.lower().replace('-', ''))]) == 2:\n",
        "                    # word = [''.join(g) for _, g in groupby(word.lower().replace('-', ''))][0][0] + [''.join(g) for _, g in groupby(word.lower().replace('-', ''))][1][0] нужно ли удалять повторы в словах типа о-о-ох\n",
        "                    word2 = re.sub(r'((\\w)(-)?)\\1+', r'\\1', word.lower().replace('-', ''))\n",
        "                    if word2 in ['ты', 'вы', 'мы', 'он', 'их', 'им', 'ей']:\n",
        "                        result = [word2, 'местоимение']\n",
        "                    elif word2 in ['че', 'чё','чо', 'шо']:\n",
        "                        result =  ['что', '']\n",
        "                    elif word2 in ['не', 'но', 'ни', 'да', 'те', 'се', 'то', 'ну']:\n",
        "                        result = [word2, '']\n",
        "                    elif word2 in prepos:\n",
        "                        result = [word2, 'предлог']\n",
        "                    elif len([''.join(g) for _, g in groupby(word.replace('-', ''))]) == 2:\n",
        "                        result = [word, 'междометие']\n",
        "\n",
        "            elif len(set(conson)) == 1 and len(set(vowels)) == 2: #ура-аа и проч. межд. c двумя гласными и согласной между ними вау\n",
        "                if len([''.join(g) for _, g in groupby(word.replace('-', ''))]) == 3 and word[0] in 'ауоыиэяюёе' and word[-1] in 'ауоыиэяюёе':\n",
        "                    word = [''.join(g) for _, g in groupby(word.replace('-', ''))][0][0] + [''.join(g) for _, g in groupby(word.replace('-', ''))][1][0] + [''.join(g) for _, g in groupby(word.replace('-', ''))][2][0]\n",
        "                    if word in ['оно', 'они', 'ему']:\n",
        "                        result = [word, 'местоимением']\n",
        "                    elif word in prepos:\n",
        "                        result = [word, 'предлог']\n",
        "                    else:\n",
        "                        result = [word, 'междометие']\n",
        "\n",
        "            elif len(set(conson)) == 2 and len(set(vowels)) == 1:\n",
        "                word2 = [''.join(g) for _, g in groupby(word.replace('-', ''))][0][0] + [''.join(g) for _, g in groupby(word.replace('-', ''))][1][0] + [''.join(g) for _, g in groupby(word.replace('-', ''))][2][0]\n",
        "                if word2 in ['мне']:\n",
        "                    result = [word2, 'местоимением']\n",
        "\n",
        "            if len(result) == 0:\n",
        "              sylls = list(map(lambda x: re.sub(r'-?(\\w)-?\\1+', r'\\1', x, re.IGNORECASE), word.lower().split('-'))) #делим слово на части и удаляем подряд идущие буквы: Ниии-ннни --> ни-ни\n",
        "              if len(sylls) == 2:\n",
        "                  if sylls[0] == sylls[1] and len(sylls[0]) == 2: #если слово состоит из двух одинаковых частей длины 2, то оно может быть как междометием (ха-ха), так и сущ.\n",
        "                    word2 = re.sub(r'((\\w)(-)?)\\1+', r'\\1', word.lower().replace('-', ''))\n",
        "                    if word2 in ['папа', 'мама', 'дядя', 'няня', 'баба']:\n",
        "                        return [word2, 'существительное']\n",
        "                    else:\n",
        "                        return [word, 'междометие']\n",
        "                  elif sylls[0] == sylls[1]:\n",
        "                      return [word, ''] #слова типа \"только-только\"\n",
        "              elif len(sylls) > 2 and len(set(sylls)) == 1: #если слово состоит из трех и более одинаковых слогов, то это, скорее всего, междометие\n",
        "                  result = [word, 'междометие']\n",
        "                  return result\n",
        "              elif sylls[0] in 'ауоыиэяюёе' and len(set(sylls[1:])) == 1: #междометия, которые начинаются с одной гласной, а остальные его части одинаковые: э-ге-ге, о-хо-хо\n",
        "                  result = [word, 'междометие']\n",
        "                  return result\n",
        "\n",
        "            if re.search(r'^ы[бвгджзклмнпрстфхцчшцьъ]', word, re.IGNORECASE): #если слово начинается с Ы, после которой следует согласный\n",
        "                result = [word, 'междометие']\n",
        "                return result\n",
        "\n",
        "            word2 = re.sub(r'-?(\\w)-?\\1+', r'\\1', word.replace('-', ''), re.IGNORECASE) #удаляем подряд идущие буквы: Ктооо-то --> ктото\n",
        "            if re.search(r'^(кто|что|че|чё|чо|шта|шо|как)$', word2, re.IGNORECASE): #восклицания вида Чтооо Каак Ктоо\n",
        "                if re.search(r'че|чё|чо|чтой|шта|што|шо', word2.lower()):\n",
        "                    word2 = re.sub(r'(че|чё|чо|чтой|шта|што|шо)', r'что', word2.lower())\n",
        "                if word2.lower() == 'как':\n",
        "                    result = [word2, 'наречие']\n",
        "                else:\n",
        "                    result = [word2, 'местоимение']\n",
        "            elif re.search(r'^(кто|что|че|чё|как|куда|когда|где|гдей|чтой|ктой|кого|кому|кого|кем|ком|чей|чего|чево|чиво|чему|чем|чём|чей|чья|чьё|чьи|чьего|чьей|чьих|чьему|чьим|чью|чьим|чьими|чьём)(то|либо|нибудь|нить|нють|нито)$', word2.lower()):\n",
        "                if re.search(r'че|чё|чо|чтой|шта|шо', word2.lower()):\n",
        "                    word = re.sub(r'(че|чё|чо|чтой|шта|што|шо)', r'что', word.lower())\n",
        "                for part in ['то', 'либо', 'нибудь', 'нить', 'нито']:\n",
        "                    if word2.endswith(part):\n",
        "                        if 'гдей' in word2:\n",
        "                            word2 = word2.replace('гдей', 'где')\n",
        "                        if word2.startswith('чтой'):\n",
        "                            word2 = word2.replace('чтой', 'что')\n",
        "                        elif word2.startswith('ктой'):\n",
        "                            word2 = word2.replace('ктой', 'кто')\n",
        "                        if part == 'то' and word2[-2:] == 'то': #исключаем случаи постановки дефиса перед первым -то (кто-то не должно переходить в к-то-то)\n",
        "                            word2 = re.sub(r'то$', '-то', word2)\n",
        "                        elif part == 'нють':\n",
        "                            word2 = word2.replace('нють', '-нибудь')\n",
        "                        elif part == 'нито':\n",
        "                            word2 = word2.replace('нито', '-нибудь')\n",
        "                        else:\n",
        "                            word2 = word2.replace(part, f'-{part}')\n",
        "                        if 'как' in word2 or 'куда' in word2 or 'когда' in word2 or 'где' in word2:\n",
        "                            result = [word2, 'наречие']\n",
        "                        else:\n",
        "                            result = [word2, 'местоимение']\n",
        "                        break\n",
        "\n",
        "            elif re.search(r'^(кое|кой|койни)(где|как|когда|куда)$', word2, re.IGNORECASE):\n",
        "                if 'койни' in word2:\n",
        "                    word2 = word2.replace('койни', 'кое')\n",
        "                for part in ['где', 'как', 'когда', 'куда']:\n",
        "                    if part in word2:\n",
        "                        word2 = word2.replace(part,  f'-{part}')\n",
        "                        break\n",
        "                result = [word2, 'местоимение']\n",
        "\n",
        "            elif re.search(r'^(кое|кой)(что|кто|чего|кого|чему|кому|чем|кем})$', word2, re.IGNORECASE):\n",
        "                word2 = re.sub(r'кое|кой|койни', 'кое-', word2, re.IGNORECASE) #выбираем именно 1ую часть, т.к. она не склоняется\n",
        "                result = [word2, 'местоимение']\n",
        "\n",
        "            elif re.search(r'^(кое|кой|койни)как(ой|ая|ое|ие|ого|их|у)$', word2, re.IGNORECASE):\n",
        "                if 'каку' in word2.lower():\n",
        "                    word2 = re.sub(r'каку', 'какую', word2)\n",
        "                word2 = re.sub(r'кое|кой|койни', 'кое-', word2, re.IGNORECASE)\n",
        "                result = [word2, 'местоимение']\n",
        "\n",
        "            elif re.search(r'^[А-Яа-яЁё]{2,}о-([А-Яа-яЁё]{2,}(о|е)-)?[А-Яа-яЁё]{2,}(ый|ой|ая|ое|ые|ие|ье|ей|ую|ого|ому|ым|им|ом|их|ее|ими|ых|его|ий|его|ему|им|ем|ыми)$', word, re.IGNORECASE): #штуки типа желто-сине-красный или синеее-ее-желтый\n",
        "                result = [word, 'прилагательное']\n",
        "\n",
        "            elif len(word.split('-')) == 2:\n",
        "                if len(word.split('-')[0]) > 4 and len(word.split('-')[1])> 4:\n",
        "                    substr = matchsubstring(word.split('-')[0], word.split('-')[1])\n",
        "                    flag = 0\n",
        "                    #если слова не пересекаются\n",
        "                    for i in range(len(substr)):\n",
        "                        if word[0].endswith(substr[i]) and word[1].startswith(substr[i]): #если конец одного слога = начало другого\n",
        "                            flag = 1\n",
        "                            break\n",
        "\n",
        "                    if word[0][-1] == word[1][0]:\n",
        "                        flag = 1\n",
        "\n",
        "                    if flag == 0:\n",
        "                        result = [word, '']\n",
        "                        return result\n",
        "\n",
        "        if len(result) != 0:\n",
        "            if cleaned_token[0].isupper(): #сохраням исходный регистр\n",
        "                result[0] = result[0].capitalize()\n",
        "            if cleaned_token[cleaned_token.find('-')+1].isupper():\n",
        "                i = result[0].find('-')+1\n",
        "                result[0] = list(result[0])\n",
        "                result[0][i] = result[0][i].upper()\n",
        "                result[0] = ''.join(result[0])\n",
        "            return result\n",
        "        else:\n",
        "            word = word.lower()\n",
        "            word = word.split('-')\n",
        "\n",
        "        if len(word) > 1:\n",
        "            syllables = []\n",
        "            for k in range(0, len(word)-1): #проходимся по слогам\n",
        "                if k == 0:\n",
        "                    syllables = [word[k]] #сразу записываем первый слог в список отфильтрованных слогов\n",
        "                substr = matchsubstring(word[k], word[k+1])\n",
        "                flag = 0\n",
        "                #исключаем часть слога, которая является общей для двух слогов\n",
        "                for i in range(len(substr)):\n",
        "                    if word[k].endswith(substr[i]) and word[k+1].startswith(substr[i]): #если конец одного слога = начало другого\n",
        "                        if word[k+1][len(substr[i])-1:] != syllables[-1] or (word[k+1][len(substr[i])-1:] != syllables[-1] and word[k+1] in ['па', 'ма', 'те', 'тё', 'дя', 'ня', 'ба']): #если слоги не одинаковые\n",
        "                            if len(word[k+1][len(substr[i]):]) > 0: #если оставшаяся длина слова больше 0\n",
        "                                syllables.append(word[k+1][len(substr[i]):])\n",
        "                            flag = 1\n",
        "\n",
        "                #последняя буква первого слога = первая буква второго слога\n",
        "                if flag == 0:\n",
        "                    if len(word[k]) > 1 and len(word[k+1]) and word[k][-1] == word[k+1][0]:\n",
        "                        if word[k+1][len(substr[i])-1:] != syllables[len(syllables)-1]:\n",
        "                            if len(word[k+1][1:]) > 1:\n",
        "                                syllables.append(word[k+1][1:])\n",
        "                                flag = 1\n",
        "                    else:\n",
        "                        #не добавляем слог, если предыдущий такой же\n",
        "                        if word[k+1] != syllables[len(syllables)-1]:\n",
        "                            syllables.append(word[k+1])\n",
        "                        flag = 1\n",
        "            #4 шаг\n",
        "            syllables2 = []\n",
        "            i = 0\n",
        "            while i < len(syllables): #склеиваем одинарные слоги\n",
        "                if len(syllables[i]) == 1: #если слог состоит из одной буквы\n",
        "                    if i != len(syllables)-1: #если этот слог не последний\n",
        "                        if len(syllables[i+1]) == 1: #если следующий слог состоит из одной буквы\n",
        "                            syllables2.append(syllables[i]+syllables[i+1]) #склеиваем подряд идущие слоги, состоящие из одной буквы\n",
        "                            i += 2\n",
        "                        else:\n",
        "                            syllables2.append(syllables[i]) #если следующий слог не одинарный, то просто добавляем текущий к слову\n",
        "                            i += 1\n",
        "                    else:\n",
        "                        syllables2.append(syllables[i])\n",
        "                        i += 1\n",
        "                else:\n",
        "                    syllables2.append(syllables[i])\n",
        "                    i += 1\n",
        "\n",
        "            syllables3 = []\n",
        "            for i in range(0,len(syllables2)):\n",
        "                if i != len(syllables2)-1:\n",
        "                    if syllables2[i] != syllables2[i+1] and not syllables2[i+1].startswith(syllables2[i]):\n",
        "                        syllables3.append(syllables2[i])\n",
        "                else:\n",
        "                    syllables3.append(syllables2[i])\n",
        "\n",
        "            #5 шаг\n",
        "            new_word = ''.join(syllables3)\n",
        "            letters = [new_word[0]]\n",
        "            for i in range(1,len(new_word)):\n",
        "                if new_word[i] != new_word[i-1]:\n",
        "                    letters.append(new_word[i])\n",
        "            new_word = ''.join(letters)\n",
        "        else:\n",
        "            letters = [word[0][0]]\n",
        "            for i in range(1,len(word[0])):\n",
        "                if word[0][i] != word[0][i-1]:\n",
        "                    letters.append(word[0][i])\n",
        "            new_word = ''.join(letters)\n",
        "\n",
        "\n",
        "        #восстанавливаем окончание имен, состоящее из двух гласных букв\n",
        "        if cleaned_token[-1] == cleaned_token[-2]:\n",
        "            if re.search(r'(.)*[бвгдзклмнпрстфх]юю$', cleaned_token) or re.search(r'(.)*[бвгджзклмнпрстфхцчшщ]ее$', cleaned_token) \\\n",
        "               or re.search(r'(.)*[бвгджзклмнпрстфхцчшщ]ии$', cleaned_token) or re.search(r'(.)*[бвгдзклмнпрстфх]яя$', cleaned_token): #если две последние буквы = допустимые окончания из двух одинаковых гласных\n",
        "                new_word += new_word[-1]\n",
        "\n",
        "        #6 шаг\n",
        "        replacements = list(set(re.findall(r'\\w[ьъ]\\w', new_word))) #находим такие сочетания, где ь или ъ находятся между двумя согласными, что недопустимо\n",
        "        for match in replacements:\n",
        "            if match[0] == match[2]: #если первая две согласные одинаковые\n",
        "                if match[0] in 'лнж': #если согласная из списка лнж = согласные, которые могут удваиваться\n",
        "                    new_word = re.sub(match, match[0]+match[2], new_word, flags=re.IGNORECASE) #заменяем льл на лл и т.д.\n",
        "                else:\n",
        "                    new_word = re.sub(match, match[0], new_word, flags=re.IGNORECASE)\n",
        "        #7 шаг\n",
        "        doubled = ['ёё', 'йй', 'шш', 'щщ', 'ъъ', 'ыы', 'ьь', 'ээ', 'аа']\n",
        "        replace_letters = {  'йа': 'я',\n",
        "                            'йюу': 'ю',\n",
        "                            'йю': 'у',\n",
        "                            'чщ': 'ч',\n",
        "                            'йе': 'е',\n",
        "                            'оа': 'о',\n",
        "                            'еэ': 'е',\n",
        "                            'юу': 'ю',\n",
        "                            'ёо': 'ё',\n",
        "                            'иы': 'и',\n",
        "                            'йё': 'ё', #йёлки\n",
        "                            'ийя': 'я',\n",
        "                            'иы': 'и',\n",
        "                            'йя': 'я'\n",
        "        }\n",
        "\n",
        "        if new_word.endswith('ыи'):\n",
        "            new_word = new_word[:-1]\n",
        "        elif new_word.endswith('йсь'):\n",
        "            new_word = re.sub(r'ь$', 'я', new_word)\n",
        "        elif new_word.endswith('ёа'):\n",
        "            new_word = re.sub(r'ёа$', 'ё', new_word)\n",
        "        elif new_word.endswith('лася'):\n",
        "            new_word = re.sub(r'ся$', 'сь', new_word)\n",
        "        if re.search(r'е(-)?(э(-)?){2,}$', cleaned_token): #ты-и\n",
        "            new_word = re.sub(r'е(-)?(э(-)?){1,}$','е', new_word)\n",
        "        elif new_word.endswith('еэ') and len(new_word) > 3:\n",
        "            new_word = re.sub(r'еэ$', 'ей', new_word) #?\n",
        "        elif new_word.endswith('уа'):\n",
        "            if re.search(r'[А-Яа-яЁё]{2,}у{1,}уа(а)?$', cleaned_token):\n",
        "                new_word = re.sub(r'уа$', 'у', new_word)\n",
        "        if re.search(r'е(-)?(о(-)?){2,}$', cleaned_token):\n",
        "            new_word = re.sub(r'е(-)?(о(-)?){1,}$','е', new_word)\n",
        "        if re.search(r'ы(-)?(и(-)?){2,}$', cleaned_token): #ты-и\n",
        "            new_word = re.sub(r'ы(-)?(и(-)?){1,}$','ы', new_word)\n",
        "        if re.search(r'нн(ый|ой|ая|ое|ые|ие|ье|ей|ую|ого|ому|ым|им|ом|их|ее|ими|ых|его|ий|его|ему|им|ем|ыми)', new_word): #восстанавливаем удвоенную согласную \"нн\"\n",
        "            index = new_word.rfind('н')\n",
        "            new_word = new_word[:index] + 'н' + new_word[index:]\n",
        "        for el in doubled:\n",
        "            if el in new_word:\n",
        "                new_word = new_word.replace(el, el[0])\n",
        "\n",
        "        for k in replace_letters.keys():\n",
        "            new_word = new_word.replace(k, replace_letters[k])\n",
        "\n",
        "        #8 шаг\n",
        "        replacements = list(set(re.findall('[аеёиоуыэюя][ьъ][аеёиоуыэюя]', new_word)))\n",
        "        for match in replacements:\n",
        "            new_word = re.sub(match, match[1], new_word, flags=re.IGNORECASE)\n",
        "\n",
        "        #9 шаг\n",
        "        replacements = list(set(re.findall('[я][аеёиоуыэю]', new_word)))\n",
        "        for match in replacements:\n",
        "            if match == 'яю':\n",
        "                if not new_word.endswith(match):\n",
        "                    new_word = re.sub(match, match[0], new_word, flags=re.IGNORECASE)\n",
        "            else:\n",
        "                new_word = re.sub(match, match[0], new_word, flags=re.IGNORECASE)\n",
        "\n",
        "        if new_word.lower() in uniq_cases['Было'].tolist():\n",
        "            new_word = uniq_cases[uniq_cases['Было'] == new_word.lower()]['Станет'].item()\n",
        "\n",
        "        if cleaned_token[0].isupper():\n",
        "            new_word = new_word.capitalize()\n",
        "\n",
        "        lemma1 = morph.parse(new_word)[0].normal_form\n",
        "        lemma2 = morph.parse(new_word)[0].normal_form.capitalize()\n",
        "        if new_word.lower() not in uniq_cases['Было'].tolist() and new_word.lower() not in vocab:\n",
        "            if lemma1 not in vocab or lemma2 not in vocab:\n",
        "                if russian.correction(new_word) is not None:\n",
        "                    new_word = russian.correction(new_word)\n",
        "\n",
        "    return [new_word, '']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9X9aH57jXqy"
      },
      "source": [
        "### **Разметка**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tags(tag,word):\n",
        "    if len(tag) == 0 and ' ' not in word:\n",
        "      return morph.parse(word)[0].tag.POS\n",
        "    elif ' ' in word:\n",
        "      return ''\n",
        "    else:\n",
        "      tags = {'существительное': 'NOUN',\n",
        "              'прилагательное': 'ADJF',\n",
        "              'наречие': 'ADVB',\n",
        "              'междометие': 'INTJ',\n",
        "              'предлог': 'PREP'\n",
        "              }\n",
        "      if tag in tags.keys():\n",
        "        return tags[tag]\n",
        "      else:\n",
        "        return tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#путь к файлу с вашими токенами\n",
        "# tokens_path = \"<ваш список токенов>.txt\"\n",
        "\n",
        "#для примера взят \"source_list.txt из нашего репозитория\"\n",
        "tokens_path = \"source_list.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ht3clsDDD5Wy"
      },
      "outputs": [],
      "source": [
        "main = []\n",
        "with open(tokens_path, 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "      if '-' in line:\n",
        "          main.append(line.replace('\\n', ''))\n",
        "\n",
        "\n",
        "data = pd.DataFrame(columns = ['Было', 'Станет', 'UPOS', 'Лемма'])\n",
        "for x in main:\n",
        "    res = get_corrected1(x)\n",
        "    if res[1] == 'междометие':\n",
        "        lemma = res[0]\n",
        "    else:\n",
        "        lemma = lemma_func(res[0])\n",
        "    data.loc[ len(data.index )] = [x, res[0], tags(res[1], res[0]), lemma]\n",
        "\n",
        "sample_df = pd.DataFrame(columns = ['Было', 'Станет', 'UPOS', 'Лемма'])\n",
        "for index, row in data.iterrows():\n",
        "    # print(row['Было'])\n",
        "    old = row['Было']; new = row['Станет']\n",
        "    if row['UPOS'] == 'INTJ':\n",
        "        sample_df.loc[ len(sample_df.index )] = [f'<w>{old}</w>', f'<distinct form=\"{old}\"><w>{new}</w></distinct>', row['UPOS'], row['Было']]\n",
        "    else:\n",
        "        lemma = row['Лемма']\n",
        "        if row['Станет'][0].isupper():\n",
        "            lemma = list(lemma)\n",
        "            lemma[0]= lemma[0].upper()\n",
        "            lemma = ''.join(lemma)\n",
        "        token_index = [match.start() for match in re.finditer('-', row['Станет'])]\n",
        "        lemma_index = [match.start() for match in re.finditer('-', lemma)]\n",
        "        k = 0\n",
        "        if len(token_index) != 0 and len(lemma_index) != 0:\n",
        "            for i in token_index:\n",
        "                if i < len(lemma)-1:\n",
        "                    if row['Станет'][i+1].isupper():\n",
        "                        lemma = list(lemma)\n",
        "                        lemma[lemma_index[k]+1] = lemma[lemma_index[k]+1].upper()\n",
        "                        lemma = ''.join(lemma)\n",
        "                k += 1\n",
        "        if len(lemma.split('-')) == 2:\n",
        "            lemma = lemma.split('-')\n",
        "            if row['Было'].split('-')[0].isupper():\n",
        "                lemma[0] = lemma[0].upper()\n",
        "            if row['Было'].split('-')[1].isupper():\n",
        "                lemma[1] = lemma[1].upper()\n",
        "            lemma = '-'.join(lemma)\n",
        "\n",
        "        sample_df.loc[len(sample_df.index )] = [f'<w>{old}</w>', f'<distinct form=\"{old}\"><w>{new}</w></distinct>', row['UPOS'], lemma]\n",
        "sample_df.to_csv('sample_df.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "aVDyS3m54Std",
        "outputId": "f8d74c9f-cf6b-4361-8998-1288bcaa14a4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Было</th>\n",
              "      <th>Станет</th>\n",
              "      <th>UPOS</th>\n",
              "      <th>Лемма</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;w&gt;Усть-Ильинск&lt;/w&gt;</td>\n",
              "      <td>&lt;distinct form=\"Усть-Ильинск\"&gt;&lt;w&gt;Усть-Ильинск&lt;...</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>Усть-Ильинск</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;w&gt;Урааа-а&lt;/w&gt;</td>\n",
              "      <td>&lt;distinct form=\"Урааа-а\"&gt;&lt;w&gt;Ура&lt;/w&gt;&lt;/distinct&gt;</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>Урааа-а</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;w&gt;маа-маа&lt;/w&gt;</td>\n",
              "      <td>&lt;distinct form=\"маа-маа\"&gt;&lt;w&gt;мама&lt;/w&gt;&lt;/distinct&gt;</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>мама</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;w&gt;светло-желтый&lt;/w&gt;</td>\n",
              "      <td>&lt;distinct form=\"светло-желтый\"&gt;&lt;w&gt;светло-желты...</td>\n",
              "      <td>ADJF</td>\n",
              "      <td>светло-жёлтый</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;w&gt;какому-то&lt;/w&gt;</td>\n",
              "      <td>&lt;distinct form=\"какому-то\"&gt;&lt;w&gt;какому-то&lt;/w&gt;&lt;/d...</td>\n",
              "      <td>ADJF</td>\n",
              "      <td>какой-то</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Было                                             Станет  \\\n",
              "0   <w>Усть-Ильинск</w>  <distinct form=\"Усть-Ильинск\"><w>Усть-Ильинск<...   \n",
              "1        <w>Урааа-а</w>     <distinct form=\"Урааа-а\"><w>Ура</w></distinct>   \n",
              "2        <w>маа-маа</w>    <distinct form=\"маа-маа\"><w>мама</w></distinct>   \n",
              "3  <w>светло-желтый</w>  <distinct form=\"светло-желтый\"><w>светло-желты...   \n",
              "4      <w>какому-то</w>  <distinct form=\"какому-то\"><w>какому-то</w></d...   \n",
              "\n",
              "   UPOS          Лемма  \n",
              "0  NOUN   Усть-Ильинск  \n",
              "1  INTJ        Урааа-а  \n",
              "2  NOUN           мама  \n",
              "3  ADJF  светло-жёлтый  \n",
              "4  ADJF       какой-то  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
